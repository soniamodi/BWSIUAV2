{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "292bdfb0",
   "metadata": {
    "editable": true,
    "id": "292bdfb0",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# BWSI UAV Course\n",
    "## Coordinate Frames & Drone Dynamics\n",
    "\n",
    "This notebook accompanies the **Controls Fundamentals** lecture (kinematics & dynamics).  \n",
    "Work through the parts in order; each builds practical skills for flying‐robot control.\n",
    "\n",
    "*Estimated effort:* 2 h in lab + 1 h write‑up\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821acf66",
   "metadata": {
    "id": "821acf66"
   },
   "source": [
    "### Learning goals\n",
    "1. Practicing Coordinate Transforms\n",
    "2. Implement and chain 3‑D frame transforms with Euler angles, rotation matrices and quaternions.  \n",
    "3. Convert sensor‑frame measurements into world‑frame velocity commands.  \n",
    "4. Size rotor thrust for hover, climb and level‑flight cruise using the point‑mass model.  \n",
    "5. Compute required pitch moment for a fast attitude step with the rigid‑body equation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qPkj4N4z2AkQ",
   "metadata": {
    "id": "qPkj4N4z2AkQ"
   },
   "source": [
    "## Part 0 - Practicing Coordinate Transforms\n",
    "In this Section we will be practicing how to transform vectors between the various reference frames used for navigating and controlling an autonomous quadrotor. For this work we will be relying heavily on the tf/transformations.py library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "SHDH8PbLfzAw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "SHDH8PbLfzAw",
    "outputId": "1be039c0-994a-4db4-9ab0-4d376e5d2242",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformations\n",
      "  Downloading transformations-2025.1.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: numpy in /home/vboxuser/miniconda3/lib/python3.13/site-packages (from transformations) (2.3.1)\n",
      "Downloading transformations-2025.1.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (145 kB)\n",
      "Installing collected packages: transformations\n",
      "Successfully installed transformations-2025.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zoM5xYLD2Rds",
   "metadata": {
    "id": "zoM5xYLD2Rds"
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import numpy as np\n",
    "import transformations as tft\n",
    "\n",
    "# Variable Notation:\n",
    "# v__x: vector expressed in \"x\" frame\n",
    "# q_x_y: quaternion of \"x\" frame with respect to \"y\" frame\n",
    "# p_x_y__z: position of \"x\" frame with respect to \"y\" frame expressed in \"z\" coordinates\n",
    "# v_x_y__z: velocity of \"x\" frame with respect to \"y\" frame expressed in \"z\" coordinates\n",
    "# R_x2y: rotation matrix that maps vector represented in frame \"x\" to representation in frame \"y\" (right-multiply column vec)\n",
    "#\n",
    "# Frame Subscripts:\n",
    "# dc = downward-facing camera (body-fixed, non-inertial frame. Origin: downward camera focal plane. Alignment with respect to drone airframe: x-forward, y-right, z-down)\n",
    "# fc = forward-facing camera (body-fixed, non-inertial frame. Origin: forward camera focal plane. Alignment with respect to drone airframe: x-right, y-down, z-forward)\n",
    "# bu = body-up frame (body-fixed, non-inertial frame. Origin: drone center of mass. Alignment with respect to drone airframe: x-forward, y-left, z-up)\n",
    "# bd = body-down frame (body-fixed, non-inertial frame. Origin: drone center of mass. Alignment with respect to drone airframe: x-forward, y-right, z-down)\n",
    "# lenu = local East-North-Up world frame (world-fixed, inertial frame. Origin: apprx at take-off point, but not guaranteed. Alignment with respect to world: x-East, y-North, z-up)\n",
    "# lned = local North-East-Down world frame (world-fixed, inertial frame. Origin: apprx at take-off point, but not guaranteed. Alignment with respect to world: x-North, y-East, z-down)\n",
    "# m = marker frame (inertial or non-inertial, depending on motion of marker. Origin: center of marker. Alignment when looking at marker: x-right, y-up, z-out of plane toward you)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "n8YKF6C-25q_",
   "metadata": {
    "editable": true,
    "id": "n8YKF6C-25q_",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "###Velocities of Relative Frames\n",
    "Just based on your understanding of what the different reference frames represent, can you find the following velocities just by inspection? Imagine there is a ball b and a drone oriented northwest. You are given that v_b_bu_fc=[1.0, 0.0, 0.0].\n",
    "\n",
    "1. v_b_bu_dc =\n",
    "2. v_b_bu_bu =\n",
    "3. v_b_bu_lned ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "W77Dw_aE3OXz",
   "metadata": {
    "editable": true,
    "id": "W77Dw_aE3OXz",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Place your answers here in markdown or comment form\n",
    "\n",
    "# YOUR CODE HERE\n",
    "#v_b_bu_dc = [0,1,0]\n",
    "#v_b_bu_bu = [0,-1,0]\n",
    "#v_b_bu_lned = [-1/root2, -1/root2, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cOLz41D13Sm2",
   "metadata": {
    "id": "cOLz41D13Sm2"
   },
   "source": [
    "###Valid Operations with Relative Frames\n",
    "Which of these operations are valid and which are invalid. If valid, write the resulting variable name. If invalid, give a brief explanation why. The first is filled out for you to show answer format:\n",
    "\n",
    "\n",
    "\n",
    "1. p_m_fc__lenu - p_bu_fc__lenu => p_m_bu__lenu\n",
    "2. np.dot(R_bu2lenu, v_bu_lenu__bu) =>\n",
    "3. np.dot(R_bu2lenu, v_bu_lenu__lenu) => invalid, R_bu2lenu maps a vector expressed in bu to a vector expressed in lenu, but v_bu_lenu__lenu is already expressed in lenu therefore this will generate a non-sensical answer\n",
    "4. v_dc_m__dc - p_m_lenu__dc =>\n",
    "5. p_bu_fc__lned - np.dot(R_m2lned, p_m_fc__m) =>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "jC_x5NL43mkn",
   "metadata": {
    "editable": true,
    "id": "jC_x5NL43mkn",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Place your answers here in markdown or comment form\n",
    "\n",
    "# YOUR CODE HERE\n",
    "  # p_m_fc__lenu - p_bu_fc__lenu => p_m_bu__lenu\n",
    "  # np.dot(R_bu2lenu, v_bu_lenu__bu) => v_bu_lenu_lenu\n",
    "  # np.dot(R_bu2lenu, v_bu_lenu__lenu) => invalid, R_bu2lenu maps a vector expressed in bu to a vector expressed in lenu, but v_bu_lenu__lenu is already expressed in lenu therefore this will generate a non-sensical answer\n",
    "  # v_dc_m__dc - p_m_lenu__dc => invalid, subtracting position from velocity\n",
    "  # p_bu_fc__lned - np.dot(R_m2lned, p_m_fc__m) => p_bu_fc_lned - p_m_fc_lned => p_bu_m_lned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46-srgvO3rzv",
   "metadata": {
    "id": "46-srgvO3rzv"
   },
   "source": [
    "###Fixed/Static Relative Rotations\n",
    "\n",
    "These rotation matrices are constant, they don't change regardless of the motion of the quadrotor. We can use this knowledge to \"hard code\" a set of transformations into a class we call `StaticTransforms` which can be used throughout our flight code.\n",
    "\n",
    "In the next code block, you will need to complete some of the components and variable definitions of the `StaticTransforms` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "zeMEG1ms4Nia",
   "metadata": {
    "editable": true,
    "id": "zeMEG1ms4Nia",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StaticTransforms():\n",
    "    def __init__(self):\n",
    "        # local ENU to local NED\n",
    "        self.R_lenu2lned = np.array([[0.0, 1.0, 0.0, 0.0],\n",
    "                                     [1.0, 0.0, 0.0, 0.0],\n",
    "                                     [0.0, 0.0, -1.0, 0.0],\n",
    "                                     [0.0, 0.0, 0.0, 1.0]])\n",
    "        # YOUR CODE HERE\n",
    "        # body-up to body-down (180-degree rotation around X-axis)\n",
    "        self.R_bu2bd = np.array([[1.0,0.0,0.0,0.0],\n",
    "                                 [0.0, -1.0, 0.0, 0.0],\n",
    "                                 [0.0,0.0,-1.0,0.0],\n",
    "                                 [0.0,0.0,0.0,1.0]])\n",
    "        # forward camera to body-down \n",
    "        self.R_fc2bd = np.array([[ 0.0, 0.0, 1.0, 0.0],\n",
    "                                 [ 0.0, 1.0, 0.0, 0.0],\n",
    "                                 [-1.0, 0.0, 0.0, 0.0],\n",
    "                                 [ 0.0, 0.0, 0.0, 1.0]])\n",
    "        # downward camera to body-down (identity)\n",
    "        self.R_dc2bd = np.eye(4)\n",
    "\n",
    "        # Derived inverse transforms\n",
    "        self.R_lned2lenu = self.R_lenu2lned.T\n",
    "        self.R_bd2bu = self.R_bu2bd.T\n",
    "        self.R_bd2fc = self.R_fc2bd.T\n",
    "        self.R_bd2dc = self.R_dc2bd.T\n",
    "\n",
    "        # Find concatenated rotation matrices from downward-camera to forward-camera\n",
    "        self.R_dc2fc = tft.concatenate_matrices(self.R_bd2fc, self.R_dc2bd)\n",
    "        self.R_fc2dc = self.R_dc2fc.T\n",
    "\n",
    "        self.R_fc2bu = tft.concatenate_matrices(self.R_bd2bu,self.R_fc2bd)\n",
    "        self.R_bu2fc = self.R_fc2bu.T\n",
    "\n",
    "        self.R_dc2bu = tft.concatenate_matrices(self.R_bd2bu, self.R_dc2bd)\n",
    "        self.R_bu2dc = self.R_dc2bu.T\n",
    "\n",
    "    def coord_transform(self, v__fin, fin, fout):\n",
    "        '''Transform vector v from fin frame to fout frame.'''\n",
    "        if fin == fout:\n",
    "            v4__fin = np.array(list(v__fin) + [0.0])#Adding the [0.0] is called *homogenizing* the\n",
    "                                                    #vector, it allows the 3D vector to be transformed by the 4D matrix\n",
    "            return v4__fin[:3]\n",
    "\n",
    "        R_str = f'R_{fin}2{fout}'\n",
    "        #check for existance of rotation matrix\n",
    "        try:\n",
    "            R_fin2fout = getattr(self, R_str)\n",
    "        except AttributeError:\n",
    "            raise AttributeError(\n",
    "                f'No static transform exists from {fin} to {fout}. '\n",
    "                'Are you sure these frames are not moving relative to each other?'\n",
    "            )\n",
    "\n",
    "        v4__fin = np.array(list(v__fin)+[0.0])\n",
    "        v4__fout = R_fin2fout @ v4__fin\n",
    "        return v4__fout[:3]\n",
    "\n",
    "st = StaticTransforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "Obawg0cn4QfK",
   "metadata": {
    "editable": true,
    "id": "Obawg0cn4QfK",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert np.allclose(st.coord_transform([1.0, 0.0, 0.0], 'bu', 'bu'), [1.0, 0.0, 0.0])\n",
    "assert np.allclose(st.coord_transform([0.08511008, 0.38572187, 0.51372079], 'dc', 'dc'), [0.08511008, 0.38572187, 0.51372079])\n",
    "assert np.allclose(st.coord_transform([0.0, 0.0, 1.0], 'fc', 'bd'), [1.0, 0.0, 0.0])\n",
    "assert np.allclose(st.coord_transform([0.0, 0.0, 1.0], 'dc', 'bu'), [0.0, 0.0, -1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fv8YEWw-4Rxi",
   "metadata": {
    "id": "fv8YEWw-4Rxi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0.]\n",
      "[1. 0. 0.]\n",
      "[0. 0. 1.]\n",
      "[ 0.147 -0.798 -1.221]\n",
      "[0.147 0.798 1.221]\n",
      "[-1.221  0.798  0.147]\n",
      "[4.853 2.979 1.884]\n",
      "[-1.884  2.979  4.853]\n",
      "[ 4.853 -2.979 -1.884]\n",
      "[1. 0. 0.]\n",
      "[ 0.  0. -1.]\n",
      "[0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Let's assume the quadrotor has some velocity v1_bd_lned__bd which is the velocity of the quadrotor\n",
    "# body-down frame with respect to the local NED world frame expressed in the body-down frame.\n",
    "# Using the fixed relative rotations, calculate it's expression in the body-up, downward-camera, and forward-camera frames\n",
    "v1_bd_lned__bd = [1.0, 0.0, 0.0]\n",
    "# YOUR CODE HERE\n",
    "transforms = StaticTransforms()\n",
    "v1_bd_lned__bu = StaticTransforms.coord_transform(transforms,v1_bd_lned__bd,\"bd\",\"bu\")\n",
    "v1_bd_lned__dc = StaticTransforms.coord_transform(transforms,v1_bd_lned__bd,\"bd\",\"dc\")\n",
    "v1_bd_lned__fc = StaticTransforms.coord_transform(transforms,v1_bd_lned__bd,\"bd\",\"fc\")\n",
    "\n",
    "print(v1_bd_lned__bu)\n",
    "print(v1_bd_lned__dc)\n",
    "print(v1_bd_lned__fc)\n",
    "\n",
    "# Let's assume the quadrotor has some velocity v2_bd_lned__bd which is the velocity of the quadrotor\n",
    "# body-down frame with respect to the local NED world frame expressed in the body-down frame.\n",
    "# Using the fixed relative rotations, calculate it's expression in the body-up, downward-camera, and forward-camera frames\n",
    "v2_bd_lned__bd = [0.147, 0.798, 1.221]\n",
    "\n",
    "v2_bd_lned__bu = StaticTransforms.coord_transform(transforms,v2_bd_lned__bd,\"bd\",\"bu\")\n",
    "v2_bd_lned__dc = StaticTransforms.coord_transform(transforms,v2_bd_lned__bd,\"bd\",\"dc\")\n",
    "v2_bd_lned__fc = StaticTransforms.coord_transform(transforms,v2_bd_lned__bd,\"bd\",\"fc\")\n",
    "\n",
    "print(v2_bd_lned__bu)\n",
    "print(v2_bd_lned__dc)\n",
    "print(v2_bd_lned__fc)\n",
    "\n",
    "# Let's assume the quadrotor has some velocity v3_dc_lenu__dc which is the velocity of the quadrotor\n",
    "# downward-camera frame with respect to the local ENU world frame expressed in the downward-camera frame.\n",
    "# Using the static transforms, calculate it's expression in the body-down, forward-camera, and body-up frames\n",
    "v3_dc_lenu__dc = [4.853, 2.979, 1.884]\n",
    "# YOUR CODE HERE\n",
    "v3_dc_lenu__bd = StaticTransforms.coord_transform(transforms,v3_dc_lenu__dc,\"dc\",\"bd\")\n",
    "v3_dc_lenu__fc = StaticTransforms.coord_transform(transforms,v3_dc_lenu__dc,\"dc\",\"fc\")\n",
    "v3_dc_lenu__bu = StaticTransforms.coord_transform(transforms,v3_dc_lenu__dc,\"dc\",\"bu\")\n",
    "\n",
    "\n",
    "print(v3_dc_lenu__bd)\n",
    "print(v3_dc_lenu__fc)\n",
    "print(v3_dc_lenu__bu)\n",
    "\n",
    "# Let's assume the quadrotor has some velocity v4_fc_lenu__bd which is the velocity of the quadrotor\n",
    "# forward-camera frame with respect to the local ENU world frame expressed in the body-down frame.\n",
    "# Using the static transforms, calculate it's expression in the forward-camera, downward-camera and and body-up frames\n",
    "v4_fc_lenu__bd = [0.0, 0.0, -1.0]\n",
    "# YOUR CODE HERE\n",
    "\n",
    "v4_fc_lenu__fc = StaticTransforms.coord_transform(transforms,v4_fc_lenu__bd,\"bd\",\"fc\")\n",
    "v4_fc_lenu__dc = StaticTransforms.coord_transform(transforms,v4_fc_lenu__bd,\"bd\",\"dc\")\n",
    "v4_fc_lenu__bu = StaticTransforms.coord_transform(transforms,v4_fc_lenu__bd,\"bd\",\"bu\")\n",
    "\n",
    "print(v4_fc_lenu__fc)\n",
    "print(v4_fc_lenu__dc)\n",
    "print(v4_fc_lenu__bu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "vtowY-B04UQC",
   "metadata": {
    "id": "vtowY-B04UQC"
   },
   "outputs": [],
   "source": [
    "# Autograder, do not modify\n",
    "\n",
    "assert np.allclose(v1_bd_lned__bd, [1.0, 0.0, 0.0])\n",
    "assert np.allclose(v2_bd_lned__bd, [0.147, 0.798, 1.221])\n",
    "assert np.allclose(v3_dc_lenu__dc, [4.853, 2.979, 1.884])\n",
    "assert np.allclose(v4_fc_lenu__bd, [0.0, 0.0, -1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "W6s2WgSB4a02",
   "metadata": {
    "id": "W6s2WgSB4a02"
   },
   "source": [
    "###Dynamic Relative Rotations\n",
    "In the previous section we looked at reference frames that remain fixed relative to one another (i.e. reference frames that are all attached to quadrotor or reference frames, or reference frames that are all associated with inertial local world frames). Now were going to look at reference frames that may be moving relative to one another, such as a body-fixed frame and the local world frame.\n",
    "\n",
    "For such moving frames, we often can't create rotation matrices by inspection. Furthermore, such rotations need to be calculated automatically by the quadrotor's flight computer in real-time. This is the job of the state estimator that runs onboard the flight computer. The state estimator will output estimates of the relative rotations between local world frame and the body frame.\n",
    "\n",
    "More specifically, the topic `mavros/local_position/pose` provides [PoseStamped](https://docs.ros.org/en/melodic/api/geometry_msgs/html/msg/PoseStamped.html) messages that contain the orientation of the body-down frame with respect to the local ENU frame in the form of a [Quaternion](https://docs.ros.org/en/melodic/api/geometry_msgs/html/msg/Quaternion.html).\n",
    "\n",
    "Therefore, when using MAVROS, you could use an assignment such as the one below to find q_bu_lenu:\n",
    "\n",
    "`q_bu_lenu = pose_stamped_msg.pose.orientation`\n",
    "\n",
    "Below is a function that we can use when flying the drone to transform vectors in an arbitrary reference frame to the local ENU reference frame, assuming that we have access to the `mavros/local_position/pose` topic to tell us `q_bu_lenu` (in this case we assume they are velocity vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "P3GbKLI35ihD",
   "metadata": {
    "id": "P3GbKLI35ihD"
   },
   "outputs": [],
   "source": [
    "def get_lenu_velocity(q_bu_lenu, v__fin, fin='bu', static_transforms=None):\n",
    "        '''tranforms a vector represented in fin frame to vector in lenu frame\n",
    "        Args:\n",
    "        - v__fin: 3D vector represented in input frame coordinates\n",
    "        - fin: string describing input coordinate frame (bd, bu, fc, dc)\n",
    "        Returns:\n",
    "        - v__lenu: 3D vector v represented in local ENU world frame\n",
    "        '''\n",
    "\n",
    "        # create static transforms if none given\n",
    "        if static_transforms is None:\n",
    "            static_transforms = StaticTransforms()\n",
    "\n",
    "        if fin=='lenu':\n",
    "            v__lenu = v__fin\n",
    "\n",
    "        elif fin=='lned':\n",
    "            v__lenu = static_transforms.coord_transform(v__fin, 'lned', 'lenu')\n",
    "\n",
    "        else:\n",
    "            # create rotation matrix from quaternion\n",
    "            R_bu2lenu = tft.quaternion_matrix(q_bu_lenu)\n",
    "\n",
    "            # represent vector v in body-down coordinates\n",
    "            v__bu = static_transforms.coord_transform(v__fin, fin, 'bu')\n",
    "\n",
    "            # calculate lenu representation of v\n",
    "            v__lenu = np.dot(R_bu2lenu, list(v__bu)+[0.0])\n",
    "\n",
    "        v__lenu = np.array(v__lenu[0:3])\n",
    "        return v__lenu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PA27KzwK5ugq",
   "metadata": {
    "id": "PA27KzwK5ugq"
   },
   "source": [
    "###ROS tf2 Library\n",
    "The problems we have attempted to address in this module (i.e. managing multiple reference frames) are by no means unique to quadrotors and we are not the first people to write functions to solve such problems. The functionality of managing different reference frames is ubiquitous throughout robotics, aerospace engineering, mechanical engineering, computer graphics, etc. and many libraries have been written for handling such functionality. When working with ROS, the most important of such libraries is the  [tf (now tf2) library](https://wiki.ros.org/tf2). While we have access to this library on the drone, we have not made use of it here because it obscures some of the underlying mathematics that we hope for you to learn and it requires additional setup steps when defining new frames that we don't intend to teach. If you are curious to know more about how ROS manages large numbers of reference frames simultaneously, we encourage you to read up more on `tf`.\n",
    "\n",
    "NOTE: `tf` in the context of ROS should not be confused with TensorFlow which is often abbreviated as tf in code. These libraries have completely different purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d31d8c",
   "metadata": {
    "id": "d4d31d8c"
   },
   "source": [
    "## Part A  Frame‑transform toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1afb736c",
   "metadata": {
    "id": "1afb736c"
   },
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "import sympy as sp\n",
    "from typing import Tuple\n",
    "#import matplotlib.pyplot as plt\n",
    "# from scipy.spatial.transform import Rotation as SciRot\n",
    "\n",
    "# ---- Constants ----\n",
    "GRAV = 9.81      # m s⁻²\n",
    "MASS = 1.0       # kg\n",
    "K_F  = 6.0e-6    # N·s²·rad⁻²\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae5cc474",
   "metadata": {
    "id": "ae5cc474"
   },
   "outputs": [],
   "source": [
    "def euler_to_rot(roll: float, pitch: float, yaw: float, order: str = \"xyz\") -> np.ndarray:\n",
    "    \"\"\"Return a 3×3 rotation matrix given Euler angles (rad).\"\"\"\n",
    "    c, s = np.cos, np.sin\n",
    "    Rx = np.array([[1,0,0],[0,c(roll),-s(roll)],[0,s(roll),c(roll)]])\n",
    "    Ry = np.array([[c(pitch),0,s(pitch)],[0,1,0],[-s(pitch),0,c(pitch)]])\n",
    "    Rz = np.array([[c(yaw),-s(yaw),0],[s(yaw),c(yaw),0],[0,0,1]])\n",
    "    mats = {\"x\":Rx, \"y\":Ry, \"z\":Rz}\n",
    "    R = np.eye(3)\n",
    "    for ax in order:\n",
    "        R = R @ mats[ax]\n",
    "    return R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc7ae0bf",
   "metadata": {
    "id": "fc7ae0bf"
   },
   "outputs": [],
   "source": [
    "def rot_to_quat(R: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Rotation matrix -> quaternion (scalar‑last).\"\"\"\n",
    "    q = np.empty(4)\n",
    "    t = np.trace(R)\n",
    "    if t > 0:\n",
    "        q[3] = np.sqrt(1 + t) / 2\n",
    "        q[0] = (R[2,1] - R[1,2]) / (4*q[3])\n",
    "        q[1] = (R[0,2] - R[2,0]) / (4*q[3])\n",
    "        q[2] = (R[1,0] - R[0,1]) / (4*q[3])\n",
    "    else:\n",
    "        i = np.argmax(np.diag(R))\n",
    "        j, k = (i+1)%3, (i+2)%3\n",
    "        q[i] = np.sqrt(1 + R[i,i] - R[j,j] - R[k,k]) / 2\n",
    "        q[3] = (R[k,j] - R[j,k]) / (4*q[i])\n",
    "        q[j] = (R[j,i] + R[i,j]) / (4*q[i])\n",
    "        q[k] = (R[k,i] + R[i,k]) / (4*q[i])\n",
    "    return q / np.linalg.norm(q)\n",
    "\n",
    "def quat_to_rot(q: np.ndarray) -> np.ndarray:\n",
    "    q = q / np.linalg.norm(q)\n",
    "    x, y, z, w = q\n",
    "    return np.array([\n",
    "        [1-2*(y**2+z**2), 2*(x*y - z*w),   2*(x*z + y*w)],\n",
    "        [2*(x*y + z*w),   1-2*(x**2+z**2), 2*(y*z - x*w)],\n",
    "        [2*(x*z - y*w),   2*(y*z + x*w),   1-2*(x**2+y**2)]\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f5bb4cb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6f5bb4cb",
    "outputId": "00ac2df1-e3bf-4321-86b4-9a6f951afe08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World‑frame velocity: [-0.7036 -0.7036  0.0995]\n"
     ]
    }
   ],
   "source": [
    "# Example transform: camera frame -> world------YOUR CODE HERE\n",
    "v_dc = np.array([0.1, 0.0, 1.0])\n",
    "R_dc2bu = euler_to_rot(np.deg2rad(0), np.deg2rad(-90), 0)\n",
    "R_bu2enu = euler_to_rot(0, 0, np.deg2rad(45))\n",
    "v_enu = R_bu2enu @ R_dc2bu @ v_dc\n",
    "v_enu /= np.linalg.norm(v_enu)\n",
    "print(\"World‑frame velocity:\", v_enu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "223f069a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "223f069a",
    "outputId": "a0071452-c60f-45bb-f26a-199ee3070602"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame‑transform sanity checks passed ✔️\n"
     ]
    }
   ],
   "source": [
    "R = euler_to_rot(0.3, -0.2, 1.0)\n",
    "assert np.allclose(R.T @ R, np.eye(3))\n",
    "q = rot_to_quat(R)\n",
    "assert np.allclose(quat_to_rot(q), R)\n",
    "print(\"Frame‑transform sanity checks passed ✔️\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9584b81",
   "metadata": {
    "id": "c9584b81"
   },
   "source": [
    "## Part B  Point‑mass thrust sizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8697e6ce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8697e6ce",
    "outputId": "e69457db-a099-441f-93bd-0ac437fb2f8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hover ω 639 rad/s\n",
      "Climb ω 671 rad/s\n",
      "Pitch ω 687 rad/s\n"
     ]
    }
   ],
   "source": [
    "def thrust_allocation(m: float, k_f: float, T_total: float) -> Tuple[float, float]:\n",
    "    per = T_total/4\n",
    "    return np.sqrt(per/k_f), per\n",
    "\n",
    "T_hover = MASS*GRAV\n",
    "ω_hov, T_per = thrust_allocation(MASS, K_F, T_hover)\n",
    "print(f\"Hover ω {ω_hov:.0f} rad/s\")\n",
    "\n",
    "#TODO: calculate w to climb at 1 m/s^2\n",
    "T_climb = MASS*(GRAV+1)\n",
    "ω_climb, T_per = thrust_allocation(MASS, K_F, T_climb)\n",
    "print(f\"Climb ω {ω_climb:.0f} rad/s\")\n",
    "\n",
    "#TODO: calculate w when pitched at 30 degrees\n",
    "T_pitch = MASS*(GRAV)/np.cos(np.radians(30))\n",
    "ω_pitch, T_per = thrust_allocation(MASS, K_F, T_pitch)\n",
    "print(f\"Pitch ω {ω_pitch:.0f} rad/s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5084af",
   "metadata": {
    "id": "6d5084af"
   },
   "source": [
    "## Part C  Rigid‑body attitude step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af0e6424",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "af0e6424",
    "outputId": "31e3832d-f07c-464f-e13d-28c051581d89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I_y 0.0083 kg·m², α 39.1 rad/s², moment 0.326 N·m\n"
     ]
    }
   ],
   "source": [
    "l,d,h = 0.3,0.2,0.1\n",
    "I_y = 1/12*MASS*np.array([[h**2+d**2,0.0,0.0],\n",
    "                     [0.0,h**2+l**2,0.0],\n",
    "                     [0.0,0.0,l**2+d**2]])\n",
    "theta = np.deg2rad(11.2); t=0.1\n",
    "alpha = 2* theta / t**2\n",
    "ω_max = alpha*t\n",
    "M_y = I_y[1][1]*alpha\n",
    "print(f\"I_y {I_y[1][1]:.4f} kg·m², α {alpha:.1f} rad/s², moment {M_y:.3f} N·m\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee8ca3c",
   "metadata": {
    "id": "fee8ca3c"
   },
   "source": [
    "---\n",
    "\n",
    "*Happy flying!* ✈️\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
